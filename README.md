# ğŸš€ Coding Assistant Chatbot

An AI-powered Coding Assistant that lets you:

- ğŸ“¤ Upload PDFs  
- ğŸ¤– Ask questions about the content  
- ğŸ§  Get LLM-powered answers (RAG + embeddings)  
- ğŸ“¥ Download your chat history  
- ğŸ§© Use a clean Streamlit UI + FastAPI backend  

This project is built using **FastAPI**, **Streamlit**, **LangChain**, **Pinecone**, and **HuggingFace Embeddings**.

---

# ğŸ¥ Demo (GIF)

Below is an AI-generated demonstration of how the app works:

![Demo GIF](A_GIF_demonstrates_an_AI-driven_Coding_Assistant_C.png)

---

# ğŸ§  Features

### âœ… Upload & process PDFs  
Documents are embedded and stored in Pinecone for semantic search.

### âœ… Chat with your documents  
Ask any question and get accurate answers powered by RAG (Retrieval-Augmented Generation).

### âœ… Streamlit UI  
Beautiful modular UI with uploader, chat component, and history downloader.

### âœ… FastAPI backend  
Handles PDF ingestion, vector DB updates, and real-time LLM inference.

### âœ… Chat history download  
Export your conversation as a text or JSON file.

---

# ğŸ“ Project Structure

Project7/
â”‚
â”œâ”€â”€ client/ # Streamlit UI
â”‚ â”œâ”€â”€ app.py # Streamlit entry point
â”‚ â”œâ”€â”€ components/ # UI components (chat, upload, history)
â”‚ â”œâ”€â”€ utils/ # API client helpers (requests)
â”‚ â””â”€â”€ config.py # API URL config
â”‚
â”œâ”€â”€ server/ # FastAPI backend
â”‚ â”œâ”€â”€ main.py # FastAPI entry point
â”‚ â”œâ”€â”€ modules/ # LLM, embeddings, loaders, handlers
â”‚ â”œâ”€â”€ routes/ # API endpoints (/ask, /upload_pdfs)
â”‚ â””â”€â”€ middlewares/ # Exception handlers
â”‚
â”œâ”€â”€ .gitignore # Git ignored files
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation


---

# ğŸ› ï¸ Tech Stack

### **Frontend**
- Streamlit  
- Custom UI components  
- Clean and modular interface  

### **Backend**
- FastAPI  
- Pydantic  
- LangChain  
- Pinecone Vector DB  
- HuggingFace Embeddings  

### **AI**
- RAG (Retrieval-Augmented Generation)  
- Context-aware LLM responses  

---

# â–¶ï¸ Getting Started

## **1ï¸âƒ£ Create virtual environment**

```bash
python -m venv venv

venv\Scripts\activate           # Windows

pip install -r requirements.txt # Install dependencies

cd server                       # Start FastAPI backend
uvicorn main:app --reload --port 8000

Uvicorn running on http://127.0.0.1:8000

